elemental double precision function relu(x)
double precision, intent(in) :: x
if(x.ge.0.D0) then
relu = x
else
relu = 0.D0
end if 
return
end function


double precision function beta_ann(data_in)
! no_inputs = 6, [ v1, v2, T/vis, v1/mfp, v2/mfp,T ]
! no_outputs = 2, [beta_av, corr_factor]
! no_layers = 2, arch = [6],[15, 2]
double precision, dimension(6), intent(in) :: data_in
double precision, dimension(6) :: data_inputs
double precision, dimension(15,6) :: weight_ann_hc_pure_1=reshape((/ &
0.265856734212345,&
0.0740910985073694,&
0.269381742813881,&
-0.670813199660335,&
1.22048994585781,&
-1.07510993620941,&
0.327585532612351,&
0.175216653261402,&
0.743569988940791,&
-0.27469084698391,&
0.254314352755543,&
0.594469288785431,&
0.339705247176319,&
-0.100392024893332,&
-0.365118769894313,&
-0.227543929497337,&
0.0438821528849261,&
0.274663992990101,&
-1.16366270392293,&
1.47779106002822,&
-1.0936764363835,&
0.316678620014099,&
-0.208295260221525,&
0.807166681497958,&
-0.251094679540092,&
0.265214830467745,&
0.658775264931788,&
-0.336187475871144,&
-0.101259065645452,&
-0.410166866142447,&
-0.000954280469321976,&
0.121085632197498,&
0.230334989289502,&
-0.111338298531968,&
0.136402619215753,&
-0.121979074224603,&
-0.00251698379473266,&
-0.00207000874221179,&
0.0718907367322471,&
-0.0926774255458571,&
0.0778196970703824,&
-0.420071237835992,&
0.00178311586225316,&
-0.438247274809891,&
-0.0217315739753533,&
0.212729155773189,&
-0.466389258080565,&
-0.440865248630318,&
0.816574556091889,&
-1.18350973000351,&
0.828923386058088,&
-0.0370002721618163,&
0.175136130315438,&
-0.5381786957396,&
0.516549761810268,&
-0.520130206498516,&
-0.454847525304779,&
0.295329097038367,&
0.275161842475654,&
0.106136486662763,&
-0.214689425241749,&
-0.49164362971007,&
-0.4425399429075,&
0.42807823997808,&
-0.986077480845984,&
0.853026767972464,&
-0.054978801971481,&
-0.158322759303553,&
-0.510398097998697,&
0.543060426788186,&
-0.518939076711009,&
-0.42660534722825,&
-0.287508341115282,&
0.274161620124611,&
0.0798947370854941,&
0.00142092778575717,&
-0.00205600400326602,&
0.000752246159206943,&
0.000232389774194845,&
-0.000458213617606326,&
0.00294731300330587,&
0.000160198248198579,&
-0.00143511203842019,&
0.00356880825618758,&
-0.0037465836356184,&
-0.011664404005346,&
0.00351282178294762,&
-0.000831057599846512,&
0.00535330135641893,&
0.000941944241354687/),shape(weight_ann_hc_pure_1))
double precision, dimension(2,15) :: weight_ann_hc_pure_2=reshape((/ &
0.414655449584298,&
0.0157128221014751,&
-0.193171556970941,&
-0.815561867336193,&
0.179587482278126,&
0.841854236185569,&
0.880924804976472,&
1.49802515518498,&
0.357509508781931,&
2.82445170745511,&
-0.215269714702372,&
2.06919282673085,&
-0.289959556855125,&
0.240116747122565,&
0.402835968477804,&
-0.0225620243283232,&
-0.084325765830665,&
1.23358948535654,&
-0.0154673503492964,&
0.923741725444246,&
-0.117153128087257,&
-0.591985071265773,&
0.00234810831554479,&
-1.3736602609859,&
0.685388483211021,&
-0.0287699945229193,&
-0.0390234231812895,&
-0.604718907329625,&
-0.586615459834816,&
0.532031319805592/),shape(weight_ann_hc_pure_2))
double precision, dimension(15) :: b_ann_hc_pure_1= (/ &
-0.176231335181446,&
0.495076102923284,&
0.290432971836888,&
0.808277180922602,&
1.22539375579,&
0.701809560647093,&
-0.0815930837583943,&
-0.298709882480968,&
-0.418772437435792,&
-0.336709600899857,&
0.163509573266538,&
-0.75454019258691,&
-0.0744195494019626,&
-0.389538685037187,&
0.249696161359229/)
double precision, dimension(2) :: b_ann_hc_pure_2= (/ &
-1.50697629486183,&
-6.89402328778163/)
double precision, dimension(6) :: min_in=(/ log10(1e-29),&
log10(1e-29),&
10044029.9460548,&
log10(3.05330945377424e-24),&
log10(2.03194352015893e-24),&
2000.0/)
double precision, dimension(6) :: max_in=(/ log10(6e-18),&
log10(3e-18),&
796606676.393839,&
log10(1.1172445975908e-10),&
log10(5.70046028197597e-11),&
4000.0/)
double precision, dimension(2) :: output_min_out=(/ log10(1.29218293858501e-15),&
-0.983350162818367 /)
double precision, dimension(2) :: output_max_out=(/ log10(6.96298450388366e-09),&
17.2811221247876/) 
double precision, dimension(15) :: x_hidden_1
double precision, dimension(2) :: beta_results


data_inputs(1) =  -1.D0+ 2.D0*(log10(data_in(1)) - min_in(1))/(max_in(1) - min_in(1))
data_inputs(2) =  -1.D0+ 2.D0*(log10(data_in(2)) - min_in(2))/(max_in(2) - min_in(2))
data_inputs(3) =  -1.D0+ 2.D0*(data_in(3) - min_in(3))/(max_in(3) - min_in(3))
data_inputs(4) =  -1.D0+ 2.D0*(log10(data_in(4)) - min_in(4))/(max_in(4) - min_in(4))
data_inputs(5) =  -1.D0+ 2.D0*(log10(data_in(5)) - min_in(5))/(max_in(5) - min_in(5))
data_inputs(6) =  -1.D0+ 2.D0*(data_in(6) - min_in(6))/(max_in(6) - min_in(6))
!LAYER 1
x_hidden_1 = matmul(weight_ann_hc_pure_1, data_inputs)
x_hidden_1 = x_hidden_1+b_ann_hc_pure_1
x_hidden_1 = relu(x_hidden_1)


!OUTPUT LAYER
beta_results = matmul(weight_ann_hc_pure_2, x_hidden_1)
beta_results = beta_results +b_ann_hc_pure_2
beta_results(1) = 0.5D0*(beta_results(1) + 1.D0)*(output_max_out(1) - output_min_out(1)) +output_min_out(1)
beta_results(1) = 10**beta_results(1)
beta_results(2) = 0.5D0*( beta_results(2)+ 1.D0)*(output_max_out(2) - output_min_out(2)) +output_min_out(2)
beta_ann = beta_results(2)*beta_results(1) + beta_results(1)
return
end function
